# urls-scrapper ğŸ”— 
## BA Internship preferences task #3

A tool for extracting the URLs from either of www.curlie.org or www.wikipedia.org recursively (i.e., including sub-pages).


### Overview ğŸ—’ï¸
URLs Scrapper is a simple tool that prompts the user for a URL and a specific depth, and it returns all the links within that page and the subpages until the specified depth, in an asynchronous matter to speed up the process. 

## Used Libraries â•
The tool utilizes the following libraries:
- __bs4__: for web scraping and parsing HTML and XML documents
- __asyncio__: for asynchronous programming
- __aiohttp__: for asynchronous http requests
- __tkinter__: for GUI

### What my code offers ğŸ¤“

- multiple depth search (determined by user)
- more websites other than the 2 required in the task
- simple GUI for testing the protoype

### Included Files ğŸ“‚

- scrapperScript.py   _Bare Script_
- gui.py    _GUI version for the tool_

### Used Programming Language ğŸ’»

<img src="https://camo.githubusercontent.com/c15141700fd20b43ada6d18c559bef630e398d0393c497586286bcb60a3bc29f/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f632f63332f507974686f6e2d6c6f676f2d6e6f746578742e7376672f3138363970782d507974686f6e2d6c6f676f2d6e6f746578742e7376672e706e67" width='40' height='40'> Python 

### author

Mariam Atef - July 2023
